{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Predictive modelling with timeseries</center>\n",
    "# <center> Part 4 - Time series forecasting with tree algorithms</center>\n",
    "\n",
    "![Image](images/timeseries.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though tree algorithms (Random forests, XGBoost, CatBoost etc.) are not the first choice that comes to mind when choosing a model to start analysing a time series, they can be extremely helpful. It is important to understand the pros and cons of choosing trees to solve timeseries problems:\n",
    "\n",
    "**PROS:** üëçüèº\n",
    "* they can handle many and varied features\n",
    "* they can handle small datasets  (keep in mind, one year of daily data is only 365 records)\n",
    "  \n",
    "**CONS:** ü•¥\n",
    "* they cannot extrapolate. You can't model a series with trend data, unless you make some adjustments through imputation and feature engineering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# jupyter lab configs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "from utils import print_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Sales prediction with the Rossman dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "rossman_df = pd.read_csv('datasets/rossman_train.csv').reset_index(drop=True)\n",
    "# set the index to the time column\n",
    "rossman_df.Date = pd.to_datetime(rossman_df.Date)\n",
    "rossman_df.head(4)\n",
    "\n",
    "# load store info\n",
    "stores = pd.read_csv('datasets/rossman_store.csv').reset_index(drop=True)\n",
    "stores.head(4)\n",
    "\n",
    "# merge store and sales\n",
    "rossman_df = pd.merge(rossman_df, stores, how='left', on='Store')\n",
    "\n",
    "# sanity check\n",
    "rossman_df = rossman_df[~((rossman_df.Sales<1)&(rossman_df.Open==1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General check of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rossman_df.Open.unique()\n",
    "rossman_df.Promo.unique()\n",
    "rossman_df.StateHoliday.unique()\n",
    "rossman_df.SchoolHoliday.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to deal with missing values?  \n",
    "You can delete them or add them via imputation. If you decide to impute the values, don't forget to keep these values so you can apply them to the test data later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    df['Year'] = df.Date.dt.year\n",
    "    df['Month'] = df.Date.dt.month\n",
    "    df['Day'] = df.Date.dt.day\n",
    "    df['DayOfWeek'] = df.Date.dt.dayofweek\n",
    "    df['WeekOfYear'] = df.Date.dt.weekofyear\n",
    "    return df\n",
    "\n",
    "def recode(df, var_list=[]):\n",
    "    map_dict = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    for v in var_list:\n",
    "        df[v].replace(map_dict, inplace=True)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot  encoding\n",
    "\n",
    "Which features should be transformed to categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any other features you wanna try out? Add them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporate the new features\n",
    "rossman_df = add_time_features(rossman_df)\n",
    "rossman_df = recode(rossman_df, ['StoreType', 'Assortment', 'StateHoliday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train, validation and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rossman_df.Date.min(), rossman_df.Date.max()\n",
    "# make sure data is sorted by date before splitting\n",
    "rossman_df = rossman_df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# let's split the data into train, validation and test\n",
    "# using two months of sales as test length\n",
    "val_start = '2015-04-01'\n",
    "test_start = '2015-06-01'\n",
    "rossman_df['dataset_type'] = ''\n",
    "rossman_df.loc[rossman_df.Date < val_start, 'dataset_type'] = 'train'\n",
    "rossman_df.loc[rossman_df.Date.between(val_start, test_start), 'dataset_type']  = 'validation'\n",
    "rossman_df.loc[rossman_df.Date >= test_start, 'dataset_type'] = 'test'\n",
    "\n",
    "train_df = rossman_df[rossman_df.dataset_type == 'train']\n",
    "val_df = rossman_df[rossman_df.dataset_type == 'validation']\n",
    "test_df = rossman_df[rossman_df.dataset_type == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(train_df[(train_df.Store<5)&(train_df.Sales>0)], x='Date', y=\"Sales\", color='Store', \n",
    "              title=\"Sales per store - training data\",  width=900, height=500,\n",
    "             hover_data = ['Open','Promo','StateHoliday','SchoolHoliday'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create baseline and check model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Sales'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists of sets of features, representing from a simple to a more complex model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = {'only_time' : ['Year', 'Month', 'Day', 'WeekOfYear', 'DayOfWeek', 'StateHoliday', 'SchoolHoliday', 'Open'],\n",
    "             'only_comp' : ['CompetitionDistance', 'Promo2', 'Open', 'Promo'],\n",
    "             'only_store' : ['StoreType', 'Assortment', 'Open', 'Store'],\n",
    "             'all_feat' : ['Year', 'Month', 'Day', 'WeekOfYear', 'DayOfWeek','StateHoliday', 'SchoolHoliday', \n",
    "                           'CompetitionDistance', 'Promo2', 'StoreType', 'Assortment', 'Open', 'Promo', 'Store']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the minimum parameters necessary to run XGBoost\n",
    "params = {\"objective\": \"reg:squarederror\", \n",
    "          \"booster\" : \"gbtree\", \n",
    "          \"seed\": 10 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_experiment(vars_list, experiment_name, params, num_boost_round):\n",
    "    dtrain = xgb.DMatrix(train_df[vars_list], label=train_df['Sales'])\n",
    "    deval = xgb.DMatrix(val_df[vars_list], label=val_df['Sales'])\n",
    "    dtest = xgb.DMatrix(test_df[vars_list], label=test_df['Sales'])\n",
    "    \n",
    "    #train\n",
    "    xgb_model = xgb.train(params, dtrain, num_boost_round=num_boost_round, \n",
    "                      early_stopping_rounds=20, evals=[(deval, \"Eval\")], verbose_eval=False)\n",
    "\n",
    "    # make prediction\n",
    "    print('+++++ Results for experiment: ', experiment_name)\n",
    "    pred = xgb_model.predict(dtest)\n",
    "    print_errors(test_df[target], pred, 'test dataset')\n",
    "    pred = xgb_model.predict(dtrain)\n",
    "    print_errors(train_df[target], pred, 'train dataset') \n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments with different combinations of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in feat_dict.keys():\n",
    "    xgboost_experiment(feat_dict[f], f, params, 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment with different number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round_list = [100, 1000, 5000]\n",
    "\n",
    "for n in num_boost_round_list:\n",
    "    print('### Experiment with ', str(n), ' boosting rounds')\n",
    "    xgboost_experiment(feat_dict['all_feat'], f, params, n)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the best set of features and another set of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"reg:squarederror\", #since it is a regression problem\n",
    "          \"booster\" : \"gbtree\",     #tree\n",
    "          \"eta\": 0.03,              #learning rate   to reduce overfitting issues\n",
    "          \"max_depth\": 10,          #depth of the tree\n",
    "          \"subsample\": 0.9,         #subsample the data prior to growing trees - overcomes overfitting\n",
    "          \"colsample_bytree\": 0.7,  #subsampling of columns for each tree\n",
    "          \"seed\": 10                \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = xgboost_experiment(feat_dict['all_feat'], 'test with different hyperparameters', params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rossman_df['predicted'] = model1.predict(xgb.DMatrix(rossman_df[feat_dict['all_feat']]))\n",
    "rossman_df['abs_error'] = np.absolute(rossman_df['predicted']  - rossman_df['Sales']) \n",
    "\n",
    "agg_dict = {'abs_error': ['mean', 'std']}\n",
    "rossman_df.groupby('dataset_type').agg(agg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A good idea is to check the model error per store type and assortment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rossman_df[rossman_df.dataset_type=='test'].groupby(['Assortment','StoreType']).agg(agg_dict).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a particular store and plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.line(rossman_df[(rossman_df.Store==379)], x='Date', y=\"Sales\", color='dataset_type', \n",
    "              title=\"Sales per store - training data\",  width=900, height=500,\n",
    "             hover_data = ['Open','Promo','StateHoliday','SchoolHoliday'])\n",
    "fig.add_trace(go.Line(x=rossman_df[(rossman_df.Store==379)].Date, y=rossman_df[(rossman_df.Store==5)].predicted,\n",
    "                    mode='lines', name='predictions'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There's a lot of room for improvement\n",
    "\n",
    " ### Repeat these experiments after implementing one-hot encoding, gridsearch..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://www.freepik.com/vectors/business'>Business vector created by freepik - www.freepik.com</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
